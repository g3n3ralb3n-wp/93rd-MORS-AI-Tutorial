{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf74e05-53b7-442c-80e1-c52a8ee85491",
   "metadata": {},
   "source": [
    "<div align=\"right\">June 2025 | &copy; JHU </div>\n",
    "\n",
    "<img src=\"./figs/ep.logo.png\" alt=\"JHU EP logo\" width=\"200\" align=\"right\" />\n",
    "\n",
    "# Retrieval-Augmented Generation\n",
    "In this example, we will build and test a simple Retrieval-Augmented Generation with Large Language Models (RAG-LLM). It typically has two main components:\n",
    "- Retriever identifies relevant context or documents from an external data source. It often uses embeddings to find and rank content based on similarity to the user's query. Popular retrievers include dense retrievers like Sentence Transformers, FAISS, or BM25-based systems. The retriever allows RAG-LLM to pull in precise and contextual information to aid the generative model in crafting accurate responses.\n",
    "- Generators usually use a large language model, such as GPT or T5, which takes the retrieved context and the user's query as input and generates a coherent, contextually relevant answer. The generator relies on the retriever-provided context to produce detailed, accurate answers to specific questions.\n",
    "\n",
    "The example below includes,\n",
    "- The external data source is from the JSON file `squad-train-v2.0.json`, which is part of the SQuAD (Stanford Question Answering Dataset) v2.0, a popular dataset for training and evaluating machine learning models on reading comprehension and question-answering tasks. Stanford released this dataset and is widely used in natural language processing (NLP) for benchmarking question-answering systems (source: &#128214; **<a href=\"https://rajpurkar.github.io/SQuAD-explorer/\" target=\"_blank\">https://rajpurkar.github.io/SQuAD-explorer/</a>**)\n",
    "- Retriever is a `Sentence Transformer` (source: &#129303; **<a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" target=\"_blank\">https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2</a>**)\n",
    "- Large Language Model (LLM) is a `Llama-3.2-1B-Instruct` model (source: &#9854;&#65039; **<a href=\"https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\" target=\"_blank\">https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct</a>**)\n",
    "\n",
    "Install the sentence transformer: `pip install sentence-transformers`&#8617;\n",
    "\n",
    "Meta requires permission to download the model, which requires an `edu` email address. As in the previous lectures, follow the instructions to request permission.\n",
    "\n",
    "Since the LLM we utilize in this example, `meta-llama/Llama-3.2-1B-Instruct`, can process the entire context, we will store only two key pieces of information: topics and contexts. At this time, we will not process `qas` section (question-answer section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7f896f-9b9b-4fa4-a45b-368d35c9f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "from IPython.display import Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "MODEL_PATH= '/EP_models/'\n",
    "os.environ['HF_HOME'] = MODEL_PATH  # before import transformers\n",
    "os.environ['HF_DATASETS_OFFLINE']= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b734aa94-10f8-4186-9477-52474176dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 2.7.0+cu126\n",
      "transformers version= 4.52.4\n",
      "CUDA available= True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# filter warnings\n",
    "import warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "Device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'transformers version= {transformers.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bd5d62-6ae8-4091-a566-39f75b7284d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c9e7a2-8af6-41d6-9873-9d3d1bc2c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 442 titles/topics in SQuAD v2.0 training dataset.\n",
      "\n",
      "Title with index #200 is Florida.\n",
      "Title Florida has 35 paragraphs. Paragraph with index 2 has 10 question-answer pairs.\n"
     ]
    }
   ],
   "source": [
    "# explore SQuAD training data structure\n",
    "with open('/EP_datasets/squad-train-v2.0.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "n_titles = len(squad_data['data'])\n",
    "print(f'There are {n_titles} titles/topics in SQuAD v2.0 training dataset.\\n')\n",
    "\n",
    "title_idx = 200\n",
    "prg_idx = 2\n",
    "current_title = squad_data['data'][title_idx]['title']\n",
    "n_paragraphs = len(squad_data['data'][title_idx]['paragraphs'])\n",
    "n_qas = len(squad_data['data'][title_idx]['paragraphs'][prg_idx]['qas'])\n",
    "print(f\"Title with index #{title_idx} is {squad_data['data'][title_idx]['title']}.\")\n",
    "print(f\"Title {current_title} has {n_paragraphs} paragraphs. Paragraph with index {prg_idx} has {n_qas} question-answer pairs.\")\n",
    "\n",
    "# docs = [entry['context'] for entry in squad_data['data'][0]['paragraphs']]\n",
    "# squad_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5428651b-3cf5-4b84-98d5-3ca123c6ac4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Florida i/ˈflɒrɪdə/ (Spanish for \"flowery land\") is a state located in the southeastern region of the United States. The state is bordered to the west by the Gulf of Mexico, to the north by Alabama and Georgia, to the east by the Atlantic Ocean, and to the south by the Straits of Florida and the sovereign state of Cuba. Florida is the 22nd most extensive, the 3rd most populous, and the 8th most densely populated of the United States. Jacksonville is the most populous city in Florida, and the largest city by area in the contiguous United States. The Miami metropolitan area is the eighth-largest metropolitan area in the United States. Tallahassee is the state capital.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squad_data['data'][200]['paragraphs'][0]['qas']\n",
    "squad_data['data'][200]['paragraphs'][0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf6e82b-47e6-4c88-8efa-5014ab7ff49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (19035, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé attended St. Mary's Elementary School ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                            context\n",
       "0  Beyoncé  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...\n",
       "1  Beyoncé  Following the disbandment of Destiny's Child i...\n",
       "2  Beyoncé  A self-described \"modern-day feminist\", Beyonc...\n",
       "3  Beyoncé  Beyoncé Giselle Knowles was born in Houston, T...\n",
       "4  Beyoncé  Beyoncé attended St. Mary's Elementary School ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqdata = {\"topic\": [], \"context\": []}\n",
    "\n",
    "for i in range(n_titles):\n",
    "    n_paragraphs = len(squad_data['data'][i]['paragraphs'])\n",
    "    for j in range(n_paragraphs):\n",
    "        sqdata[\"topic\"].append(squad_data['data'][i]['title'])\n",
    "        sqdata[\"context\"].append(squad_data['data'][i]['paragraphs'][j]['context'])\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(sqdata)\n",
    "\n",
    "# sanity\n",
    "print(f'Shape of df: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b54619-189d-4b50-9919-e2863ad11845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGLLM:\n",
    "    def __init__(self, external_data):\n",
    "        self.st_model = SentenceTransformer('all-MiniLM-L6-v2')  # sentence transformer is used for embeddings\n",
    "        \n",
    "        # external data\n",
    "        self.external_data = external_data\n",
    "        self.titles = self.external_data['topic'].unique()\n",
    "        self.title_embeddings = self.st_model.encode(self.titles.tolist())  # embed each topic/title\n",
    "\n",
    "        # LLM model\n",
    "        self.generator = pipeline('text-generation', model='meta-llama/Llama-3.2-1B-Instruct',\n",
    "                                  max_length=4096, device=Device)  # utilize GPU in this example\n",
    "\n",
    "    def generate_answer(self, user_question):\n",
    "        # Step 1: Find the best matching topic\n",
    "        question_embedding = self.st_model.encode([user_question])\n",
    "        title_similarities = cosine_similarity(question_embedding, self.title_embeddings)\n",
    "        best_title_index = np.argmax(title_similarities)\n",
    "        best_title = self.titles[best_title_index]\n",
    "        print(f\"The best topic: {best_title}\\n\")\n",
    "\n",
    "        # Step 2: Filter contexts for the identified best topic\n",
    "        topic_contexts = self.external_data[self.external_data['topic'] == best_title]['context'].tolist()\n",
    "\n",
    "        # Step 3: Vectorize each context under the best topic and find the best matching context\n",
    "        context_embeddings = self.st_model.encode(topic_contexts)\n",
    "        context_similarities = cosine_similarity(question_embedding, context_embeddings)\n",
    "        best_context_index = np.argmax(context_similarities)\n",
    "        best_context = topic_contexts[best_context_index]\n",
    "        print(f\"The best paragraph: {best_context}\\n\")\n",
    "\n",
    "        # Step 4: Generate the answer using LLM with retrieved context\n",
    "        prompt = f\"Context: {best_context}\\n\\nQuestion: {user_question}\\nAnswer:\"\n",
    "        response = self.generator(prompt, max_length=300)\n",
    "        answer_text = response[0]['generated_text']\n",
    "        answer = answer_text.split(\"Answer: \")[-1] \n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6bbd8cf-3da2-4596-a496-bd508307b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: United_States_presidential_election,_2004\n",
      "\n",
      "The best paragraph: Just eight months into his presidency, the terrorist attacks of September 11, 2001 suddenly transformed Bush into a wartime president. Bush's approval ratings surged to near 90%. Within a month, the forces of a coalition led by the United States entered Afghanistan, which had been sheltering Osama bin Laden, suspected mastermind of the September 11 attacks. By December, the Taliban had been removed as rulers of Kabul, although a long and ongoing reconstruction would follow, severely hampered by ongoing turmoil and violence within the country.\n",
      "\n",
      "Barack Obama.\n",
      "Context: The question is a factual one, and the answer is based on the events of the past eight months. The US president in 2012 was Barack Obama, the 44th President of the United States. This is a fact that can be verified by checking the presidential election results from 2012, which were widely reported in the media.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the US president in 2012?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac36d5-d710-4f95-adf7-252d99a62f71",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. The best topic from the external data source appears to be relevant, although the year in the best topic is 2004, while the question asks about 2012. The best paragraph mentions only President Bush, but the answer is Barack Obama which is correct.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b503a05-a973-46ea-9677-03eafccd95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Geography_of_the_United_States\n",
      "\n",
      "The best paragraph: By total area (water as well as land), the United States is either slightly larger or smaller than the People's Republic of China, making it the world's third or fourth largest country. China and the United States are smaller than Russia and Canada in total area, but are larger than Brazil. By land area only (exclusive of waters), the United States is the world's third largest country, after Russia and China, with Canada in fourth. Whether the US or China is the third largest country by total area depends on two factors: (1) The validity of China's claim on Aksai Chin and Trans-Karakoram Tract. Both these territories are also claimed by India, so are not counted; and (2) How US calculates its own surface area. Since the initial publishing of the World Factbook, the CIA has updated the total area of United States a number of times.\n",
      "\n",
      "Alaska. Alaska has the largest state area in the United States by\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the largest state in USA by area?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa98a-8a25-4e3c-a797-9795c4fac9df",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is incorrect. The best topic from the external data source appears to be relevant. However, the best paragraph is quite off. It is also possible that the chosen topic wasn't the most relevant one. From the paragraph, we can see that the geography of the US basically discusses the geography of the US as a country, not its individual states. The information about the largest state in the US by area is possibly in the Alaska topic.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352e8152-b320-4625-9fcc-dc0d1d9248c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Alaska\n",
      "\n",
      "The best paragraph: Alaska (i/əˈlæskə/) is a U.S. state situated in the northwest extremity of the Americas. The Canadian administrative divisions of British Columbia and Yukon border the state to the east while Russia has a maritime border with the state to the west across the Bering Strait. To the north are the Chukchi and Beaufort Seas, the southern parts of the Arctic Ocean. To the south and southwest is the Pacific Ocean. Alaska is the largest state in the United States by area, the 3rd least populous and the least densely populated of the 50 United States. Approximately half of Alaska's residents (the total estimated at 738,432 by the Census Bureau in 2015) live within the Anchorage metropolitan area. Alaska's economy is dominated by the fishing, natural gas, and oil industries, resources which it has in abundance. Military bases and tourism are also a significant part of the economy.\n",
      "\n",
      "Alaska. Alaska is the largest state in the USA by area, covering approximately 663,268 square miles. Texas covers approximately 268,597 square miles.\n"
     ]
    }
   ],
   "source": [
    "query = \"Which state is larger by area in the USA: Alaska or Texas?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c4487-7775-4968-ae3a-b299f9b1fd14",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. Both the best topic and the best paragraph from the external data source are on point.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b69891-4565-4a97-9792-6696c46aa9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Florida\n",
      "\n",
      "The best paragraph: The United States Census Bureau estimates that the population of Florida was 20,271,272 on July 1, 2015, a 7.82% increase since the 2010 United States Census. The population of Florida in the 2010 census was 18,801,310. Florida was the seventh fastest-growing state in the U.S. in the 12-month period ending July 1, 2012. In 2010, the center of population of Florida was located between Fort Meade and Frostproof. The center of population has moved less than 5 miles (8 km) to the east and approximately 1 mile (1.6 km) to the north between 1980 and 2010 and has been located in Polk County since the 1960 census. The population exceeded 19.7 million by December 2014, surpassing the population of the state of New York for the first time.\n",
      "\n",
      "20,271,272\n",
      "Year: 2015\n",
      "Population: 20,271,272\n",
      "Percentage increase: 7.82%\n",
      "Year: 2010\n",
      "Population: 18,801,310\n",
      "Percentage increase: 7.82%\n",
      "Year: 2012\n",
      "Population: 19,333,919\n",
      "Percentage increase: 7.82%\n",
      "Year: 2010\n",
      "Center of population: between Fort Meade and Frostproof\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the population of Florida?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bede8f3-44fa-460f-8901-bc7b51a77e9f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. This question is quite general, as it does not mention a specific timeline. Therefore, the answer depends on how recent the external data source is. The last update to the SQuAD 2.0 dataset was in 2018. Hence, it makes sense that the output returned the population of Florida in 2015. Both the best topic and the best paragraph are relevant to the question.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c0f2c7-626c-4c03-9e00-404d4ce24739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best topic: Appalachian_Mountains\n",
      "\n",
      "The best paragraph: In Pennsylvania, there are over sixty summits that rise over 2,500 ft (800 m); the summits of Mount Davis and Blue Knob rise over 3,000 ft (900 m). In Maryland, Eagle Rock and Dans Mountain are conspicuous points reaching 3,162 ft (964 m) and 2,882 ft (878 m) respectively. On the same side of the Great Valley, south of the Potomac, are the Pinnacle 3,007 feet (917 m) and Pidgeon Roost 3,400 ft (1,000 m). In West Virginia, more than 150 peaks rise above 4,000 ft (1,200 m), including Spruce Knob 4,863 ft (1,482 m), the highest point in the Allegheny Mountains. A number of other points in the state rise above 4,800 ft (1,500 m). Snowshoe Mountain at Thorny Flat 4,848 ft (1,478 m) and Bald Knob 4,842 ft (1,476 m) are among the more notable peaks in West Virginia.\n",
      "\n",
      "Mount Rushmore is located in the Black Hills of South Dakota, not Pennsylvania, Maryland, or West Virginia.\n",
      "Explanation: This question requires the student to analyze the information provided and identify the correct location of Mount Rushmore. The student must recognize that the other locations listed\n"
     ]
    }
   ],
   "source": [
    "query = \"Where is Mount Rushmore?\"\n",
    "ragllm = RAGLLM(df)\n",
    "output = ragllm.generate_answer(query)\n",
    "for part in output.split(\"\\n\\n\"):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471e69d-be38-41e2-bfb6-ca5fa0786a97",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "Analysis: The output is correct. However, the best topic and the best paragraph in the external dataset are not relevant.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a91395-a7f6-422a-ba34-9259b733b906",
   "metadata": {},
   "source": [
    "## Analysis and Observations\n",
    "The main purpose of the example above is to demonstrate a simple implementation of the RAG with an LLM. While this approach is useful, there are areas for improvement. Key points include:\n",
    "1. External Dataset Update: The SQuAD 2.0 training dataset was last updated in 2018, while the Llama-3.2-1B-Instruct model was last updated in September 2024. As a result, the pre-trained LLM contains more recent information and data.\n",
    "2. Dataset Limitations: The external dataset SQuAD 2.0 training dataset may have limitations that can cause the LLM to rely on pre-trained data instead of the external dataset for some outputs. This reflects the constraints of relying on solely static external sources.\n",
    "3. Efficiency of Updates: In practice, updating external datasets is more efficient and optimized compared to updating the entire pre-trained data in an LLM. This efficiency contributes to the growing popularity and practicality of RAG-LLMs.\n",
    "***\n",
    "## Why RAG-LLM Is Better Than LLM Alone?\n",
    "Using RAG-LLM is often better than using an LLM alone because RAG combines the strengths of both retrieval-based systems and generative language models. Here's why it can be advantageous:\n",
    "1. Up-to-Date Knowledge: Accesses external, real-time data; LLMs rely on static, pre-training knowledge.\n",
    "2. Improved Accuracy: Grounds responses in retrieved documents, reducing hallucinations.\n",
    "3. Domain-Specific Flexibility: Tailored to specific domains by indexing relevant data.\n",
    "4. Reduced Training Costs: Updates only the retrieval database, avoiding LLM retraining.\n",
    "5. Transparency: Provides references or sources for answers, enhancing trust.\n",
    "6. Cost Efficiency: Uses smaller models with retrieval for similar or better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b7709-eb3f-4bbb-b825-d857ae65e20a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F1E0D6; padding: 10px; border-radius: 5px;\">\n",
    "In the example below, we will illustrate Domain-Specific Flexibility. In the SQuAD dataset, under the 'Florida' topic, 'Florida' is mentioned with its meaning as 'flower' in Spanish. This information is quite specific and possibly unique. However, the pre-trained dataset of LLaMA may be more general. Therefore, while an LLM may not be able to answer the question correctly, a RAG-LLM will be able to do so in the Explanation part.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71b27dd-c8cc-4818-8257-f1adf79333f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLaMAQA:\n",
    "    def __init__(self, model_name='meta-llama/Llama-3.2-1B-Instruct'):\n",
    "        self.model_name = model_name\n",
    "        print(f\"Loading model '{model_name}'...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def ask_question(self, question, max_length=50, temperature=0.7, top_p=0.9, top_k=50):\n",
    "        \"\"\"\n",
    "        Ask a question and get a response from the model.\n",
    "        Parameters:\n",
    "            question (str): The question to ask.\n",
    "            max_length (int): Maximum length of the response.\n",
    "            temperature (float): Sampling temperature for randomness.\n",
    "            top_p (float): Nucleus sampling parameter.\n",
    "            top_k (int): Top-k sampling parameter.\n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(question, return_tensors=\"pt\")\n",
    "        \n",
    "        # generate the response\n",
    "        outputs = self.model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            do_sample=True\n",
    "        )\n",
    "        # decode and return the response\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9947f3b2-1e03-4e4e-a720-3e66645fabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'meta-llama/Llama-3.2-1B-Instruct'...\n",
      "Q: What does 'Florida' mean in Spanish?\n",
      "A: What does 'Florida' mean in Spanish? \n",
      "The word 'Florida' in Spanish means \"flower.\" It is derived from the Spanish word \"flor,\" which refers to a flower. The name is often used as a metaphor for the state\n"
     ]
    }
   ],
   "source": [
    "llama_qa = LLaMAQA()\n",
    "\n",
    "query = \"What does 'Florida' mean in Spanish?\"\n",
    "response = llama_qa.ask_question(query)\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2871910-1670-44f2-b27b-ffbd3a9d6241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {margin-left: 0 !important;}\n",
       "    p {font-family: verdana;}\n",
       "    li {font-family: verdana;}\n",
       "    div {font-size: 10pt;}\n",
       "</style>\n",
       "<!-- Display markdown tables left oriented in this notebook. -->\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {margin-left: 0 !important;}\n",
    "    p {font-family: verdana;}\n",
    "    li {font-family: verdana;}\n",
    "    div {font-size: 10pt;}\n",
    "</style>\n",
    "<!-- Display markdown tables left oriented in this notebook. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da4bd1-05a8-4759-b2dc-a0b4bc934886",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
